{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Project Idea:\n",
        "* This project involves scraping data from Booking.com, a website that allows travellers to book hotels in various cities worldwide.\n",
        "\n",
        "* By scraping data from this website, we can collect information about hotels like their name, type of room, location, etc., and use machine learning algorithms to train a model that learns various features of the hotels and predicts the prices."
      ],
      "metadata": {
        "id": "FdWW4mtPyW30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import the Necesarry libraries"
      ],
      "metadata": {
        "id": "fIaJ9OXByRdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install libraries\n",
        "!pip install selectorlib requests beautifulsoup4 pandas scikit-learn tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C9Ta3ilMypEc",
        "outputId": "1daf823a-bc30-49ee-ef75-6f841ba90565"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selectorlib in /usr/local/lib/python3.12/dist-packages (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from selectorlib) (8.3.0)\n",
            "Requirement already satisfied: pyyaml>=3.12 in /usr/local/lib/python3.12/dist-packages (from selectorlib) (6.0.3)\n",
            "Requirement already satisfied: parsel>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from selectorlib) (1.10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from parsel>=1.5.1->selectorlib) (1.3.0)\n",
            "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from parsel>=1.5.1->selectorlib) (1.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from parsel>=1.5.1->selectorlib) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from parsel>=1.5.1->selectorlib) (25.0)\n",
            "Requirement already satisfied: w3lib>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from parsel>=1.5.1->selectorlib) (2.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FfMo2iHcw8P3"
      },
      "outputs": [],
      "source": [
        "#Import the libraries for the project\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selectorlib import Extractor\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "from urllib.parse import urljoin, urlencode, urlparse, parse_qs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Create the YAML extractor for SelectorLib\n",
        "\n",
        "* A YAML file (with the .yaml or .yml extension) is a human-readable data serialization format used for storing and exchanging data — similar to JSON or XML, but simpler and easier to read.\n",
        "* Note: Booking.com HTML changes frequently. You will likely need to tweak selectors for your target region / page layout. Use the browser inspector to verify CSS paths.\n"
      ],
      "metadata": {
        "id": "v-CnYUFK0jFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write the YAML file\n",
        "selectors_yaml = \"\"\"\n",
        "# Selectors for Booking.com (list page) - NOTE: these are approximate and may need adjusting.\n",
        "list:\n",
        "  hotels:\n",
        "    css: \"div[data-testid='property-card']\"\n",
        "    type: list\n",
        "    children:\n",
        "      name:\n",
        "        css: \"div[data-testid='title']\"\n",
        "        xpath: null\n",
        "        type: text\n",
        "      url:\n",
        "        css: \"a[data-testid='title-link']\"\n",
        "        type: attribute\n",
        "        attribute: href\n",
        "      rating:\n",
        "        css: \"div[aria-label*='Scored']\"\n",
        "        type: text\n",
        "      price:\n",
        "        css: \"span[data-testid='price-and-discounted-price']\"\n",
        "        type: text\n",
        "      review_count:\n",
        "        css: \"div[data-testid='reviews-number']\"\n",
        "        type: text\n",
        "      location_snippet:\n",
        "        css: \"span[data-testid='distance']\"\n",
        "        type: text\n",
        "\n",
        "# Selectors for hotel details page\n",
        "detail:\n",
        "  name:\n",
        "    css: \"h2[data-testid='title']\"\n",
        "    type: text\n",
        "  address:\n",
        "    css: \"span[data-testid='address']\"\n",
        "    type: text\n",
        "  overall_review_score:\n",
        "    css: \"div[data-testid='review-score-component'] div[aria-hidden='false']\"\n",
        "    type: text\n",
        "  review_count:\n",
        "    css: \"div[data-testid='review-score-component'] span\"\n",
        "    type: text\n",
        "  star_rating:\n",
        "    css: \"span[class*='bd73d']\"    # may need updating\n",
        "    type: text\n",
        "  amenities:\n",
        "    css: \"div[data-testid='hotel-facilities'] li\"\n",
        "    type: list\n",
        "    children:\n",
        "      amenity:\n",
        "        css: \"div\"\n",
        "        type: text\n",
        "  room_types:\n",
        "    css: \"table[class*='hprt-table'] tr\"\n",
        "    type: list\n",
        "    children:\n",
        "      room_type:\n",
        "        css: \"td[class*='hprt-roomtype']\"\n",
        "        type: text\n",
        "  price_from:\n",
        "    css: \"div[data-testid='price-and-discounted-price']\"\n",
        "    type: text\n",
        "  latitude:\n",
        "    css: \"meta[property='booking:location:latitude']\"\n",
        "    type: attribute\n",
        "    attribute: content\n",
        "  longitude:\n",
        "    css: \"meta[property='booking:location:longitude']\"\n",
        "    type: attribute\n",
        "    attribute: content\n",
        "\"\"\"\n",
        "open(\"booking_selectors.yml\", \"w\", encoding=\"utf-8\").write(selectors_yaml)\n",
        "print(\"Wrote booking_selectors.yml\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cOL9edAzLh0",
        "outputId": "12501e7e-2605-41f0-94de-4d390f41d077"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote booking_selectors.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Basic HTTP session with polite headers, retry and delay"
      ],
      "metadata": {
        "id": "CPvLPNjg1Fm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SESSION = requests.Session()\n",
        "# rotate between a few user agents\n",
        "USER_AGENTS = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15\",\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0 Safari/537.36\",\n",
        "]\n",
        "HEADERS = {\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
        "    \"User-Agent\": random.choice(USER_AGENTS),\n",
        "}\n",
        "\n",
        "def polite_get(url, params=None, max_retries=3, sleep_range=(2,5)):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            headers = HEADERS.copy()\n",
        "            headers[\"User-Agent\"] = random.choice(USER_AGENTS)\n",
        "            resp = SESSION.get(url, params=params, headers=headers, timeout=15)\n",
        "            if resp.status_code == 200:\n",
        "                # small random delay\n",
        "                time.sleep(random.uniform(*sleep_range))\n",
        "                return resp.text\n",
        "            else:\n",
        "                # backoff\n",
        "                time.sleep(2 + attempt)\n",
        "        except Exception as e:\n",
        "            time.sleep(2 + attempt)\n",
        "    raise Exception(f\"Failed to GET {url} after {max_retries} tries\")\n"
      ],
      "metadata": {
        "id": "BHHjZG6PzPVF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Function to extract hotels from a search/list page"
      ],
      "metadata": {
        "id": "KNlnZWiq1ZSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selectorlib import Extractor\n",
        "extractor = Extractor.from_yaml_file('booking_selectors.yml')\n",
        "\n",
        "def parse_search_page(html):\n",
        "    data = extractor.extract(html)\n",
        "    # data['hotels'] should be a list of hotel blocks\n",
        "    hotels = data.get('hotels') or []\n",
        "    # normalize prices/ratings strings\n",
        "    normalized = []\n",
        "    for h in hotels:\n",
        "        # ensure URL is absolute\n",
        "        url = h.get('url') or ''\n",
        "        if url and url.startswith('/'):\n",
        "            url = urljoin(\"https://www.booking.com\", url)\n",
        "        h['url'] = url\n",
        "        normalized.append(h)\n",
        "    return normalized\n"
      ],
      "metadata": {
        "id": "xruimFBXzTx7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Function to parse detail page (hotel page)"
      ],
      "metadata": {
        "id": "5YuJOAko1fY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_detail_page(html):\n",
        "    data = extractor.extract(html)  # using the detail rules too\n",
        "    # extractor returns both list and detail keys; focus on detail-level keys\n",
        "    detail = data\n",
        "    # Clean/normalize a few fields\n",
        "    if 'amenities' in detail and isinstance(detail['amenities'], list):\n",
        "        detail['amenities'] = [a.strip() for a in detail['amenities'] if a and a.strip()]\n",
        "    if 'room_types' in detail and isinstance(detail['room_types'], list):\n",
        "        # Extract text only\n",
        "        rooms = []\n",
        "        for r in detail['room_types']:\n",
        "            if isinstance(r, dict):\n",
        "                rooms.append(r.get('room_type','').strip())\n",
        "            else:\n",
        "                rooms.append(str(r).strip())\n",
        "        detail['room_types'] = [r for r in rooms if r]\n",
        "    return detail\n"
      ],
      "metadata": {
        "id": "VNoxDPCYzWnz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Putting it together: scrape N pages of search results for a city"
      ],
      "metadata": {
        "id": "ERYJPU4z1lz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_search_url(city, checkin=None, checkout=None, page=0):\n",
        "    # Basic Booking search URL with query param ss\n",
        "    base = \"https://www.booking.com/searchresults.html\"\n",
        "    params = {\"ss\": city, \"offset\": page*25}  # offset controlled by page\n",
        "    if checkin:\n",
        "        params.update(checkin)   # optional dict\n",
        "    return base + \"?\" + urlencode(params)\n",
        "\n",
        "def scrape_city(city, pages=2, max_hotels=None):\n",
        "    results = []\n",
        "    for p in range(pages):\n",
        "        url = build_search_url(city, page=p)\n",
        "        print(\"Fetching list page:\", url)\n",
        "        html = polite_get(url)\n",
        "        hotels = parse_search_page(html)\n",
        "        print(f\"Found {len(hotels)} hotels on page {p}\")\n",
        "        for h in hotels:\n",
        "            # attempt to fetch hotel detail page if URL exists\n",
        "            hotel_data = dict(h)  # start with list-level fields\n",
        "            detail_url = h.get('url')\n",
        "            if detail_url:\n",
        "                try:\n",
        "                    detail_html = polite_get(detail_url)\n",
        "                    detail_parsed = parse_detail_page(detail_html)\n",
        "                    hotel_data.update(detail_parsed)\n",
        "                except Exception as e:\n",
        "                    print(\"Failed to fetch detail:\", e)\n",
        "            results.append(hotel_data)\n",
        "            if max_hotels and len(results) >= max_hotels:\n",
        "                return results\n",
        "        # tiny pause between pages\n",
        "        time.sleep(random.uniform(5,10))\n",
        "    return results\n",
        "\n",
        "# Example run (small)\n",
        "# hotels_data = scrape_city(\"Nairobi\", pages=1, max_hotels=10)\n",
        "# pd.DataFrame(hotels_data).head()\n"
      ],
      "metadata": {
        "id": "qzaP9pnlzbZK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Save results to CSV"
      ],
      "metadata": {
        "id": "fIEwnV1V12OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(data, filename):\n",
        "    \"\"\"Saves a list of dictionaries to a CSV file.\"\"\"\n",
        "    if not data:\n",
        "        print(\"No data to save.\")\n",
        "        return None\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(f\"{filename}.csv\", index=False)\n",
        "    print(f\"Saved {len(data)} records to {filename}.csv\")\n",
        "    return df\n",
        "\n",
        "# Scrape some data (example: 1 page of results for Nairobi)\n",
        "hotels_data = scrape_city(\"Nairobi\", pages=1)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "df = save_results(hotels_data, \"booking_nairobi_results\")\n",
        "\n",
        "# List files to show the CSV was created\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "QCZhSgzm2IDU",
        "outputId": "2109431a-d4f3-4ce8-a0e3-b7037a7566e7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching list page: https://www.booking.com/searchresults.html?ss=Nairobi&offset=0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Failed to GET https://www.booking.com/searchresults.html?ss=Nairobi&offset=0 after 3 tries",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2229922435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Scrape some data (example: 1 page of results for Nairobi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhotels_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nairobi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Save the data to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1378075353.py\u001b[0m in \u001b[0;36mscrape_city\u001b[0;34m(city, pages, max_hotels)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_search_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fetching list page:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolite_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mhotels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_search_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(hotels)} hotels on page {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1805788164.py\u001b[0m in \u001b[0;36mpolite_get\u001b[0;34m(url, params, max_retries, sleep_range)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to GET {url} after {max_retries} tries\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mException\u001b[0m: Failed to GET https://www.booking.com/searchresults.html?ss=Nairobi&offset=0 after 3 tries"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " NOTE:\n",
        " * The code was unable to fetch the content of the specified URL after multiple attempts.\n",
        " * This is because the website we are trying to scrape (Booking.com in this case) is actively blocking the requests.\n",
        " * Websites often implement measures to prevent automated scraping."
      ],
      "metadata": {
        "id": "cBX6kC4K3df8"
      }
    }
  ]
}